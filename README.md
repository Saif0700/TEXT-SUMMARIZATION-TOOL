# TEXT-SUMMARIZATION-TOOL

*COMPANY*: CODTECH IT SOLUTIONS

*NAME*: MOHD SAIF ALI

*INTERN ID*: CT04DL854

*DOMAIN*: ARTIFICIAL INTELLIGENCE

*DURATION*: 4 WEEKS

*MENTOR*: NEELA SANTOSH

This Python script demonstrates how to generate a concise summary of a given article using the Latent Semantic Analysis (LSA) text summarization algorithm from the Sumy library. The primary objective of the script is to automate the process of condensing long-form text into shorter, meaningful summaries that retain the essential information. The code is organized into modular functions for better readability, clarity, and reusability. It illustrates a standard workflow in natural language processing (NLP) applications where raw text is processed, tokenized, analyzed, and then summarized using an algorithmic approach. The summarization process uses several key components from the Sumy library. First, the PlaintextParser class is used to convert raw textual input into a format that the summarizer can understand. This parser handles the initial processing and structuring of the text data. It reads the content and prepares it for further transformation. Next, the Tokenizer class is used to break the input text into smaller units such as sentences and words. Tokenization is a critical step in natural language processing as it allows the system to analyze the structure and meaning of text more effectively. In this script, the tokenizer is specifically set for the English language. The main summarization is performed by the LsaSummarizer class. This component implements the Latent Semantic Analysis (LSA) algorithm, a well-established unsupervised machine learning method. LSA works by identifying patterns and relationships between terms and sentences within the text. It does this by creating a term-document matrix and then reducing its dimensionality using a technique called Singular Value Decomposition (SVD). This mathematical reduction allows the model to capture the most important underlying concepts in the text, which are then used to determine which sentences are most representative of the entire document. The summarize_text function encapsulates this logic. It takes in raw text as input and allows the user to specify how many sentences should be included in the summary, with a default of five. It first parses and tokenizes the text, then applies the LSA summarizer to extract the most relevant sentences. These selected sentences are then converted into a single output string using a join operation. The main function serves as a wrapper for summarize_text, simplifying its usage. It receives a block of article text, sends it to the summarizer, and returns the summary. This abstraction is useful for integrating the summarizer into larger projects or applications. A sample article is included to demonstrate how the summarization works. This article discusses the benefits of regular physical exercise, including types of workouts such as aerobic, strength training, flexibility, and balance exercises. It also highlights how exercise can prevent chronic diseases, improve mood, enhance sleep, and boost energy. The text is stored in a variable called article, formatted as a multiline string. When passed to the main() function, it is summarized efficiently using the LSA approach. Finally, both the original article and the resulting summary are printed to the console for comparison. This allows users to verify the effectiveness of the summarization process. Overall, this script serves as a practical example of how structured Python code and NLP tools like Sumy can be used to perform automatic text summarization. Its modular design and reliance on proven algorithms make it an excellent starting point for students, developers, and researchers working in the field of text analysis and information retrieval.
